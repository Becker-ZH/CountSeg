{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weakly Supervised Instance Segmentation using Class Peak Response \n",
    "### Evaluation code of object counting in Pascal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nest import modules, run_tasks\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrmse(non_zero,count_pred, count_gt):\n",
    "    ## compute mrmse\n",
    "    nzero_mask=torch.ones(count_gt.size())\n",
    "    if non_zero==1:\n",
    "        nzero_mask=torch.zeros(count_gt.size())\n",
    "        nzero_mask[count_gt!=0]=1\n",
    "    mrmse=torch.pow(count_pred - count_gt, 2)\n",
    "    mrmse = torch.mul(mrmse, nzero_mask)\n",
    "    mrmse = torch.sum(mrmse, 0)\n",
    "    nzero = torch.sum(nzero_mask, 0)\n",
    "    mrmse = torch.div(mrmse, nzero)\n",
    "    mrmse = torch.sqrt(mrmse)\n",
    "    mrmse = torch.mean(mrmse)\n",
    "    return mrmse\n",
    "\n",
    "def rel_mrmse(non_zero,count_pred, count_gt):\n",
    "    ## compute reltive mrmse\n",
    "    nzero_mask=torch.ones(count_gt.size())\n",
    "    if non_zero==1:\n",
    "        nzero_mask=torch.zeros(count_gt.size())\n",
    "        nzero_mask[count_gt!=0]=1\n",
    "    num = torch.pow(count_pred - count_gt, 2)\n",
    "    denom = count_gt.clone()\n",
    "    denom = denom+1\n",
    "    rel_mrmse = torch.div(num, denom)\n",
    "    rel_mrmse = torch.mul(rel_mrmse, nzero_mask)\n",
    "    rel_mrmse = torch.sum(rel_mrmse, 0)\n",
    "    nzero = torch.sum(nzero_mask, 0)\n",
    "    rel_mrmse = torch.div(rel_mrmse, nzero)\n",
    "    rel_mrmse = torch.sqrt(rel_mrmse)\n",
    "    rel_mrmse = torch.mean(rel_mrmse)\n",
    "    return rel_mrmse\n",
    "\n",
    "def return_count_obj_rm_diff(xml_file,class_name):\n",
    "    count=0\n",
    "    tree = ET.parse(xml_file)\n",
    "    objs = tree.findall('object')\n",
    "    for ix, obj in enumerate(objs):\n",
    "        if obj.find('name').text==class_name and int(obj.find('difficult').text)==0:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# object categories\n",
    "class_names = modules.pascal_voc_object_categories()\n",
    "image_size = 448\n",
    "# image pre-processor\n",
    "transformer = modules.image_transform(\n",
    "    image_size = [image_size, image_size],\n",
    "    augmentation = dict(),\n",
    "    mean = [0.485, 0.456, 0.406],\n",
    "    std = [0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set pascal 2007 dataset path \n",
    "pascal_path='/raid/xiaoke/pascal_2007/VOCdevkit/VOC2007'\n",
    "\n",
    "## load pascal 2007 test image list\n",
    "with open(pascal_path+'/ImageSets/Main/test.txt','r') as f:\n",
    "    image_list=[]\n",
    "    for ima in f:\n",
    "        ima=ima.strip('\\n')\n",
    "        image_list.append(ima)\n",
    "\n",
    "## get the ground truth count\n",
    "class_names = modules.pascal_voc_object_categories()\n",
    "num_classes=len(class_names)\n",
    "class_labels = OrderedDict()\n",
    "for class_idx in range(num_classes):\n",
    "    filename = os.path.join(\n",
    "        pascal_path+'/ImageSets/Main/', class_names[class_idx] + '_' + 'test' + '.txt')\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            name, label = line.split()\n",
    "            if name not in class_labels:\n",
    "                class_labels[name] = np.zeros(num_classes)\n",
    "            class_labels[name][class_idx] = int(label)\n",
    "            if int(label)!=-1:\n",
    "                count=return_count_obj_rm_diff(os.path.join(pascal_path+'/Annotations/',name+'.xml'),\n",
    "                    class_names[class_idx])\n",
    "                class_labels[name][class_idx] = int(count)\n",
    "            else:\n",
    "                class_labels[name][class_idx] = int(0)\n",
    "gt_count=[]\n",
    "for i in list(class_labels.items()):\n",
    "    gt_count.append(i[1])\n",
    "gt_count=np.array(gt_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function PeakResponseMapping._median_filter at 0x7efc65170048>\n",
      "addedmodule5\n",
      "enable_peak_stimulation on\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "tensor(1.1474)\n",
      "tensor(0.6134)\n",
      "tensor(0.2991)\n",
      "tensor(0.1836)\n"
     ]
    }
   ],
   "source": [
    "backbone = modules.fc_resnet50(channels=60, pretrained=False)\n",
    "model = modules.peak_response_mapping(backbone,enable_peak_stimulation=True,peak_stimulation='addedmodule5',\n",
    "                                     sub_pixel_locating_factor=1)\n",
    "# loaded pre-trained weights\n",
    "model = nn.DataParallel(model)\n",
    "state = torch.load('../models/counting/pascal07.pt')\n",
    "model.load_state_dict(state['model'])\n",
    "model = model.module.cuda()\n",
    "model = model.eval()\n",
    "pred_count=[]\n",
    "for index_d,ima in enumerate(image_list):\n",
    "    if index_d%500==0:\n",
    "        print(index_d)\n",
    "    raw_img = Image.open(pascal_path+'/JPEGImages/'+str(ima)+'.jpg').convert('RGB')\n",
    "    width, height=raw_img.size\n",
    "    input_var = transformer(raw_img).unsqueeze(0).cuda().requires_grad_()\n",
    "    confidence,class_response_map1,peak = model(input_var,1)\n",
    "    confidence=confidence.cpu().detach().numpy()\n",
    "    count_one = F.adaptive_avg_pool2d(class_response_map1, 1).squeeze(2).squeeze(2).detach().cpu().numpy()[0]\n",
    "    confidence[confidence<0]=0\n",
    "    confidence=confidence[0]\n",
    "    confidence[confidence>0]=1\n",
    "    pred_count.append(np.round(confidence*count_one))\n",
    "pred_count=np.array(pred_count)\n",
    "print(mrmse(1,torch.from_numpy(pred_count).float(), torch.from_numpy(gt_count).float()))\n",
    "print(rel_mrmse(1,torch.from_numpy(pred_count).float(), torch.from_numpy(gt_count).float()))\n",
    "print(mrmse(0,torch.from_numpy(pred_count).float(), torch.from_numpy(gt_count).float()))\n",
    "print(rel_mrmse(0,torch.from_numpy(pred_count).float(), torch.from_numpy(gt_count).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "ssap_exp_config": {
   "error_alert": "Error Occurs!",
   "initial": [],
   "max_iteration": 1,
   "recv_id": "",
   "running": [],
   "summary": [],
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
